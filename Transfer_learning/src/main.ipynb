{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset import preprocess_data\n",
    "\n",
    "# preprocess_data(src_dir=\"../data/raw\", out_dir=\"../data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- fold 1 -----\n",
      "epoch 1: train loss: 0.801 train accuracy: 0.291 validation loss: 0.542 validation accuracy: 0.912\n",
      "epoch 2: train loss: 0.604 train accuracy: 0.719 validation loss: 0.617 validation accuracy: 0.684\n",
      "epoch 3: train loss: 0.482 train accuracy: 0.875 validation loss: 0.699 validation accuracy: 0.579\n",
      "epoch 4: train loss: 0.407 train accuracy: 0.91 validation loss: 0.798 validation accuracy: 0.474\n",
      "epoch 5: train loss: 0.336 train accuracy: 0.947 validation loss: 0.798 validation accuracy: 0.509\n",
      "----- fold 2 -----\n",
      "epoch 1: train loss: 0.52 train accuracy: 0.812 validation loss: 1.012 validation accuracy: 0.053\n",
      "epoch 2: train loss: 0.428 train accuracy: 0.822 validation loss: 1.117 validation accuracy: 0.07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDenseNet121\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m MyTraniner(model, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.000005\u001b[39m, epoch\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, kfold\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\tsx10\\PythonProjectsJupyter\\TUM\\FP\\trainning_dense121\\src\\train.py:212\u001b[0m, in \u001b[0;36mMyTraniner.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkfold is not valid.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 212\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_fold_train()\n",
      "File \u001b[1;32mc:\\Users\\tsx10\\PythonProjectsJupyter\\TUM\\FP\\trainning_dense121\\src\\train.py:188\u001b[0m, in \u001b[0;36mMyTraniner.k_fold_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalloader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, sampler\u001b[39m=\u001b[39mval_sampler)\n\u001b[0;32m    186\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 188\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch()\n\u001b[0;32m    189\u001b[0m     val_loss, val_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_epoch()\n\u001b[0;32m    190\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepoch \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m: train loss: \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m train accuracy: \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m validation loss: \u001b[39m\u001b[39m{3}\u001b[39;00m\u001b[39m validation accuracy: \u001b[39m\u001b[39m{4}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(epoch, \u001b[39mround\u001b[39m(train_loss, \u001b[39m3\u001b[39m), \u001b[39mround\u001b[39m(train_accuracy, \u001b[39m3\u001b[39m), \u001b[39mround\u001b[39m(val_loss, \u001b[39m3\u001b[39m), \u001b[39mround\u001b[39m(val_accuracy, \u001b[39m3\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\tsx10\\PythonProjectsJupyter\\TUM\\FP\\trainning_dense121\\src\\train.py:102\u001b[0m, in \u001b[0;36mMyTraniner.train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(imgs)\n\u001b[0;32m    101\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(outputs, labels)\n\u001b[1;32m--> 102\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    105\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\tsx10\\anaconda3\\envs\\Computer_Vision\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tsx10\\anaconda3\\envs\\Computer_Vision\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import MyTraniner\n",
    "\n",
    "model = \"DenseNet121\"\n",
    "trainer = MyTraniner(model, batch_size=4, learning_rate=0.000005, epoch=10, kfold=10, cuda=True)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

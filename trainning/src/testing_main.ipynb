{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def delete_files_in_folder(folder_path):\n",
    "    shutil.rmtree(folder_path)\n",
    "\n",
    "delete_files_in_folder(r\"C:\\Users\\tsx10\\PythonProjectsJupyter\\TUM\\FP\\Images\\trainning\\data\")\n",
    "\n",
    "# prepare folder\n",
    "folder_names = [\"test/0\", \"test/1\", \"train/0\", \"train/1\"]\n",
    "\n",
    "for name in folder_names:\n",
    "    os.makedirs(\"../data/processed/mini MNIST npy/\" + name, exist_ok=True)\n",
    "\n",
    "for name in folder_names:\n",
    "    os.makedirs(\"../data/raw/mini MNIST JPG/\" + name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the traing data\n",
    "\n",
    "from data import split_test_train_dataset\n",
    "\n",
    "folder_path = r\"C:\\Users\\tsx10\\PythonProjectsJupyter\\TUM\\FP\\Images\\split_images_11.06.23\"\n",
    "split_test_train_dataset(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0\n",
      "processing 1\n",
      "processing 0\n",
      "processing 1\n"
     ]
    }
   ],
   "source": [
    "# preprocessing images in npy files\n",
    "\n",
    "from preprocessing import preprocess_mini_mnist\n",
    "\n",
    "preprocess_mini_mnist(\"../data/raw/mini MNIST JPG\", out_dir=\"../data/processed/mini MNIST npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 1 | tr loss: 0.565 | vl loss: 0.6215 | tr acc.: 0.7171 | vl acc.: 0.7257 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 2 | tr loss: 0.551 | vl loss: 0.6436 | tr acc.: 0.7322 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 3 | tr loss: 0.5452 | vl loss: 0.6381 | tr acc.: 0.7387 | vl acc.: 0.7522 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 4 | tr loss: 0.5107 | vl loss: 0.5813 | tr acc.: 0.7516 | vl acc.: 0.7345 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 5 | tr loss: 0.4764 | vl loss: 0.4655 | tr acc.: 0.7538 | vl acc.: 0.7788 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 6 | tr loss: 0.4762 | vl loss: 0.4349 | tr acc.: 0.7495 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 7 | tr loss: 0.4577 | vl loss: 0.4464 | tr acc.: 0.7689 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 8 | tr loss: 0.4343 | vl loss: 0.486 | tr acc.: 0.7797 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 9 | tr loss: 0.4271 | vl loss: 0.4256 | tr acc.: 0.7819 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 10 | tr loss: 0.446 | vl loss: 0.4091 | tr acc.: 0.7905 | vl acc.: 0.7699 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 11 | tr loss: 0.416 | vl loss: 0.4204 | tr acc.: 0.7948 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 12 | tr loss: 0.4005 | vl loss: 0.3884 | tr acc.: 0.8078 | vl acc.: 0.7788 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 13 | tr loss: 0.3997 | vl loss: 0.3406 | tr acc.: 0.8078 | vl acc.: 0.823 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 14 | tr loss: 0.387 | vl loss: 0.3858 | tr acc.: 0.8078 | vl acc.: 0.7876 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 15 | tr loss: 0.4159 | vl loss: 0.5693 | tr acc.: 0.8294 | vl acc.: 0.7611 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 16 | tr loss: 0.4013 | vl loss: 0.335 | tr acc.: 0.8251 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 17 | tr loss: 0.3675 | vl loss: 0.3354 | tr acc.: 0.8467 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 18 | tr loss: 0.3646 | vl loss: 0.3155 | tr acc.: 0.838 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 19 | tr loss: 0.3727 | vl loss: 0.3067 | tr acc.: 0.8402 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 20 | tr loss: 0.3666 | vl loss: 0.317 | tr acc.: 0.8488 | vl acc.: 0.823 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 21 | tr loss: 0.346 | vl loss: 0.3451 | tr acc.: 0.838 | vl acc.: 0.7965 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 22 | tr loss: 0.3778 | vl loss: 0.2961 | tr acc.: 0.8423 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 23 | tr loss: 0.3643 | vl loss: 0.3495 | tr acc.: 0.8488 | vl acc.: 0.8142 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 24 | tr loss: 0.3772 | vl loss: 0.4162 | tr acc.: 0.8359 | vl acc.: 0.7699 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 25 | tr loss: 0.348 | vl loss: 0.2964 | tr acc.: 0.851 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 26 | tr loss: 0.3421 | vl loss: 0.2889 | tr acc.: 0.8726 | vl acc.: 0.8407 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 27 | tr loss: 0.3301 | vl loss: 0.3302 | tr acc.: 0.8618 | vl acc.: 0.823 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 28 | tr loss: 0.3212 | vl loss: 0.2863 | tr acc.: 0.8618 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 29 | tr loss: 0.3153 | vl loss: 0.2808 | tr acc.: 0.8661 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 30 | tr loss: 0.308 | vl loss: 0.2785 | tr acc.: 0.8618 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 31 | tr loss: 0.3079 | vl loss: 0.2806 | tr acc.: 0.8639 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 32 | tr loss: 0.3211 | vl loss: 0.2832 | tr acc.: 0.8639 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 33 | tr loss: 0.2961 | vl loss: 0.285 | tr acc.: 0.8812 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 34 | tr loss: 0.2942 | vl loss: 0.2756 | tr acc.: 0.8855 | vl acc.: 0.8673 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 35 | tr loss: 0.2922 | vl loss: 0.2795 | tr acc.: 0.8769 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 36 | tr loss: 0.3166 | vl loss: 0.3028 | tr acc.: 0.8747 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 37 | tr loss: 0.292 | vl loss: 0.3419 | tr acc.: 0.8963 | vl acc.: 0.8142 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 38 | tr loss: 0.2874 | vl loss: 0.2542 | tr acc.: 0.8963 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 39 | tr loss: 0.3054 | vl loss: 0.2603 | tr acc.: 0.879 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 40 | tr loss: 0.308 | vl loss: 0.2598 | tr acc.: 0.8985 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 41 | tr loss: 0.288 | vl loss: 0.2742 | tr acc.: 0.8812 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 42 | tr loss: 0.2815 | vl loss: 0.285 | tr acc.: 0.8963 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 43 | tr loss: 0.2625 | vl loss: 0.2826 | tr acc.: 0.8877 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 44 | tr loss: 0.2712 | vl loss: 0.267 | tr acc.: 0.8812 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 45 | tr loss: 0.2655 | vl loss: 0.29 | tr acc.: 0.892 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 46 | tr loss: 0.2652 | vl loss: 0.2975 | tr acc.: 0.8855 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 47 | tr loss: 0.2707 | vl loss: 0.2887 | tr acc.: 0.8985 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 48 | tr loss: 0.2737 | vl loss: 0.269 | tr acc.: 0.9028 | vl acc.: 0.8407 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 49 | tr loss: 0.2733 | vl loss: 0.2759 | tr acc.: 0.8898 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 50 | tr loss: 0.274 | vl loss: 0.2791 | tr acc.: 0.905 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 51 | tr loss: 0.2674 | vl loss: 0.3039 | tr acc.: 0.8834 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 52 | tr loss: 0.2546 | vl loss: 0.3237 | tr acc.: 0.9093 | vl acc.: 0.8407 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 53 | tr loss: 0.2418 | vl loss: 0.4802 | tr acc.: 0.9201 | vl acc.: 0.7876 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 54 | tr loss: 0.2423 | vl loss: 0.2734 | tr acc.: 0.905 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 55 | tr loss: 0.2456 | vl loss: 0.3285 | tr acc.: 0.9179 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 56 | tr loss: 0.2443 | vl loss: 0.2417 | tr acc.: 0.9222 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 57 | tr loss: 0.2412 | vl loss: 0.3628 | tr acc.: 0.9093 | vl acc.: 0.8319 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 58 | tr loss: 0.2297 | vl loss: 0.2744 | tr acc.: 0.9028 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 59 | tr loss: 0.2205 | vl loss: 0.2378 | tr acc.: 0.9309 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 60 | tr loss: 0.2287 | vl loss: 0.2477 | tr acc.: 0.9222 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 61 | tr loss: 0.2746 | vl loss: 0.3305 | tr acc.: 0.9114 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 62 | tr loss: 0.2278 | vl loss: 0.2731 | tr acc.: 0.9266 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 63 | tr loss: 0.2321 | vl loss: 0.2456 | tr acc.: 0.9244 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 64 | tr loss: 0.2215 | vl loss: 0.2416 | tr acc.: 0.9222 | vl acc.: 0.8407 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 65 | tr loss: 0.2375 | vl loss: 0.2424 | tr acc.: 0.9287 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 66 | tr loss: 0.2101 | vl loss: 0.242 | tr acc.: 0.9438 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 67 | tr loss: 0.206 | vl loss: 0.2455 | tr acc.: 0.9395 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 68 | tr loss: 0.2032 | vl loss: 0.2462 | tr acc.: 0.9352 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 69 | tr loss: 0.2101 | vl loss: 0.2397 | tr acc.: 0.9266 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 70 | tr loss: 0.2056 | vl loss: 0.2421 | tr acc.: 0.9222 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 71 | tr loss: 0.2035 | vl loss: 0.3201 | tr acc.: 0.933 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 72 | tr loss: 0.2003 | vl loss: 0.264 | tr acc.: 0.933 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 73 | tr loss: 0.191 | vl loss: 0.3324 | tr acc.: 0.9287 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 74 | tr loss: 0.2044 | vl loss: 0.2598 | tr acc.: 0.9244 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 75 | tr loss: 0.2034 | vl loss: 0.2469 | tr acc.: 0.9352 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 76 | tr loss: 0.2145 | vl loss: 0.2586 | tr acc.: 0.946 | vl acc.: 0.885 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 77 | tr loss: 0.2189 | vl loss: 0.2499 | tr acc.: 0.933 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 78 | tr loss: 0.205 | vl loss: 0.3002 | tr acc.: 0.9438 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 79 | tr loss: 0.196 | vl loss: 0.2805 | tr acc.: 0.9395 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 80 | tr loss: 0.2015 | vl loss: 0.2655 | tr acc.: 0.9395 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 81 | tr loss: 0.1885 | vl loss: 0.2906 | tr acc.: 0.9417 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 82 | tr loss: 0.1965 | vl loss: 0.2491 | tr acc.: 0.9417 | vl acc.: 0.9204 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 83 | tr loss: 0.1914 | vl loss: 0.229 | tr acc.: 0.9374 | vl acc.: 0.8761 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 84 | tr loss: 0.1772 | vl loss: 0.4289 | tr acc.: 0.9395 | vl acc.: 0.7965 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 85 | tr loss: 0.1943 | vl loss: 0.2489 | tr acc.: 0.933 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 86 | tr loss: 0.1729 | vl loss: 0.2942 | tr acc.: 0.946 | vl acc.: 0.8496 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 87 | tr loss: 0.1866 | vl loss: 0.4933 | tr acc.: 0.9417 | vl acc.: 0.7699 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 88 | tr loss: 0.1767 | vl loss: 0.2169 | tr acc.: 0.9525 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 89 | tr loss: 0.21 | vl loss: 0.2485 | tr acc.: 0.9395 | vl acc.: 0.9204 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 90 | tr loss: 0.1843 | vl loss: 0.22 | tr acc.: 0.959 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 91 | tr loss: 0.1545 | vl loss: 0.2565 | tr acc.: 0.9698 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 92 | tr loss: 0.1785 | vl loss: 0.2355 | tr acc.: 0.9438 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 93 | tr loss: 0.1694 | vl loss: 0.2499 | tr acc.: 0.9503 | vl acc.: 0.9115 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 94 | tr loss: 0.162 | vl loss: 0.2192 | tr acc.: 0.9654 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 95 | tr loss: 0.1789 | vl loss: 0.4013 | tr acc.: 0.9482 | vl acc.: 0.8142 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 96 | tr loss: 0.1621 | vl loss: 0.2634 | tr acc.: 0.9611 | vl acc.: 0.8584 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 97 | tr loss: 0.1548 | vl loss: 0.3017 | tr acc.: 0.9546 | vl acc.: 0.8673 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 98 | tr loss: 0.1494 | vl loss: 0.2131 | tr acc.: 0.9503 | vl acc.: 0.8938 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 99 | tr loss: 0.1447 | vl loss: 0.2166 | tr acc.: 0.9568 | vl acc.: 0.9027 | \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 100 | tr loss: 0.1735 | vl loss: 0.3269 | tr acc.: 0.9503 | vl acc.: 0.8407 | \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "minimum working example:\n",
    "performs classification on mini MNIST\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "from data import MyDataset, AddNoiseToTensor\n",
    "from model import MyModel\n",
    "from workflow import MyTrainer\n",
    "\n",
    "USE_CUDA = True\n",
    "\n",
    "def main():\n",
    "\n",
    "    with open(r\"C:\\Users\\tsx10\\PythonProjectsJupyter\\TUM\\FP\\Images\\trainning\\data\\processed\\mini MNIST npy\\data.json\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # get paths and labels\n",
    "    tr_paths = [sample[\"path\"] for sample in data[\"train\"]]\n",
    "    tr_labels = [sample[\"label\"] for sample in data[\"train\"]]\n",
    "    vl_paths = [sample[\"path\"] for sample in data[\"test\"]]\n",
    "    vl_labels = [sample[\"label\"] for sample in data[\"test\"]]\n",
    "\n",
    "    # build data augmentations\n",
    "    # (torchvision transforms also provides many different pre-built augmentation and conversion transforms)\n",
    "    tr_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=data[\"info\"][\"mean\"], std=data[\"info\"][\"std\"])\n",
    "        # AddNoiseToTensor(p=0.5, alpha=0.01)\n",
    "    ])\n",
    "\n",
    "    vl_transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=data[\"info\"][\"mean\"], std=data[\"info\"][\"std\"])\n",
    "    ])\n",
    "\n",
    "    # build datasets and dataloaders\n",
    "    # dataloaders handle batching of samples and multiprocessing (cores defined by num_workers)\n",
    "    trainset = MyDataset(paths=tr_paths, labels=tr_labels, transform=tr_transform)\n",
    "    valset = MyDataset(paths=vl_paths, labels=vl_labels, transform=vl_transform)\n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=0)\n",
    "    valloader = DataLoader(valset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    # define model\n",
    "    model = MyModel(in_channels=3, num_classes=2, channels=32, num_blocks=4)\n",
    "    if USE_CUDA:\n",
    "        model.cuda()  # .cuda() just pushes model to first available gpu device, alternative: model.to(<device_name>)\n",
    "\n",
    "    # define optimizer after pushing model to device\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=None, reduction=\"mean\")\n",
    "\n",
    "    # define trainer\n",
    "    t = MyTrainer(model=model,\n",
    "                  trainloader=trainloader,\n",
    "                  valloader=valloader,\n",
    "                  optim=optimizer,\n",
    "                  crit=criterion,\n",
    "                  cuda=USE_CUDA)\n",
    "\n",
    "    # let's gooo!\n",
    "    t.train(epochs=100)\n",
    "    t.save_model(\"../saved_weights/test_003.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 001: in_channels=3, num_classes=2, channels=32, num_blocks=4 ||epoch 100 | tr loss: 0.2234 | vl loss: 0.261 | tr acc.: 0.9071 | vl acc.: 0.9027 | \n",
    "# 002: in_channels=3, num_classes=2, channels=64, num_blocks=4 ||epoch 100 | tr loss: 0.1616 | vl loss: 1.8543 | tr acc.: 0.9698 | vl acc.: 0.4336 |  overfitting\n",
    "# 003: in_channels=3, num_classes=2, channels=32, num_blocks=6 ||epoch 100 | tr loss: 0.1735 | vl loss: 0.3269 | tr acc.: 0.9503 | vl acc.: 0.8407 | "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
